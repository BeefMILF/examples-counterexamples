{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/nnets/lib/python3.5/site-packages/h5py/__init__.py:34: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "\n",
    "import keras.backend as K\n",
    "from keras.layers import Dense, Input, Activation\n",
    "from keras.models import Model\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from src.fetch_mnist import preprocessed_mnist"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Useful links\n",
    "\n",
    "# TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Preparing data\n",
    "\n",
    "We'll use MNIST dataset. Examples are standardised according to training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/nnets/lib/python3.5/site-packages/sklearn/utils/validation.py:429: DataConversionWarning: Data with input dtype uint8 was converted to float64 by StandardScaler.\n",
      "  warnings.warn(msg, _DataConversionWarning)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train_labels, y_test_labels = preprocessed_mnist(random_state=0)\n",
    "X_test, X_valid, y_test_labels, y_valid_labels = train_test_split(X_test, y_test_labels, test_size=0.5) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "ohe = OneHotEncoder()\n",
    "\n",
    "y_train = ohe.fit_transform(y_train_labels.reshape(-1, 1)).toarray()\n",
    "y_test = ohe.transform(y_test_labels.reshape(-1, 1)).toarray()\n",
    "y_valid = ohe.transform(y_valid_labels.reshape(-1, 1)).toarray()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic regression with softmax using `module` API"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`keras.layers` contains `Layers` - abstractions that behave like neural network layers, and can be used as functions of tensors (note, for example usage of `Dense` layer), or appended in sequential models.\n",
    "\n",
    "`keras.models` contains `Model` class - it provides high-level functionalities a'la `scikit-learn` estimators. `Model`s wrap Keras tensors. \n",
    "\n",
    "Below is an example of simple *Model* that performs logistic regression (it uses minibatch gradient descent for optimization)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_shape = (X_train.shape[1],)\n",
    "n_classes = y_train.shape[1]\n",
    "\n",
    "softmax_input =  Input(shape=input_shape)\n",
    "softmax_intermediate = Dense(n_classes)(softmax_input)\n",
    "softmax_output = Activation('softmax')(softmax_intermediate) \n",
    "\n",
    "logistic_classifier = Model(inputs=[softmax_input], outputs=[softmax_output])\n",
    "\n",
    "logistic_classifier.compile(optimizer='adam', loss=['categorical_crossentropy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following cell contains code that can be passed to our Module's `fit` method. It is used to save per-batch metric (here accuracy is used)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 56000 samples, validate on 7000 samples\n",
      "Epoch 1/100\n",
      "56000/56000 [==============================] - 2s 43us/step - loss: 0.5420 - val_loss: 0.3447\n",
      "Epoch 2/100\n",
      "56000/56000 [==============================] - 2s 39us/step - loss: 0.3213 - val_loss: 0.3107\n",
      "Epoch 3/100\n",
      "56000/56000 [==============================] - 2s 35us/step - loss: 0.2964 - val_loss: 0.3003\n",
      "Epoch 4/100\n",
      "56000/56000 [==============================] - 2s 33us/step - loss: 0.2833 - val_loss: 0.2997\n",
      "Epoch 5/100\n",
      "56000/56000 [==============================] - 2s 34us/step - loss: 0.2753 - val_loss: 0.2944\n",
      "Epoch 6/100\n",
      "56000/56000 [==============================] - 2s 33us/step - loss: 0.2687 - val_loss: 0.2955\n",
      "Epoch 7/100\n",
      "56000/56000 [==============================] - 2s 32us/step - loss: 0.2649 - val_loss: 0.2946\n",
      "Epoch 8/100\n",
      "56000/56000 [==============================] - 2s 33us/step - loss: 0.2614 - val_loss: 0.2950\n",
      "Epoch 9/100\n",
      "56000/56000 [==============================] - 2s 33us/step - loss: 0.2588 - val_loss: 0.2957\n",
      "Epoch 10/100\n",
      "56000/56000 [==============================] - 2s 33us/step - loss: 0.2556 - val_loss: 0.2943\n",
      "Epoch 11/100\n",
      "56000/56000 [==============================] - 2s 34us/step - loss: 0.2540 - val_loss: 0.2967\n",
      "Epoch 12/100\n",
      "56000/56000 [==============================] - 2s 33us/step - loss: 0.2517 - val_loss: 0.2955\n",
      "Epoch 13/100\n",
      "56000/56000 [==============================] - 2s 33us/step - loss: 0.2498 - val_loss: 0.2997\n",
      "Epoch 14/100\n",
      "56000/56000 [==============================] - 2s 33us/step - loss: 0.2491 - val_loss: 0.2992\n",
      "Epoch 15/100\n",
      "56000/56000 [==============================] - 2s 34us/step - loss: 0.2477 - val_loss: 0.3009\n",
      "Epoch 16/100\n",
      "56000/56000 [==============================] - 2s 33us/step - loss: 0.2459 - val_loss: 0.2990\n",
      "Epoch 17/100\n",
      "56000/56000 [==============================] - 2s 33us/step - loss: 0.2449 - val_loss: 0.3011\n",
      "Epoch 18/100\n",
      "56000/56000 [==============================] - 2s 34us/step - loss: 0.2439 - val_loss: 0.3004\n",
      "Epoch 19/100\n",
      "56000/56000 [==============================] - 2s 33us/step - loss: 0.2431 - val_loss: 0.3041\n",
      "Epoch 20/100\n",
      "56000/56000 [==============================] - 2s 34us/step - loss: 0.2417 - val_loss: 0.3009\n",
      "Epoch 21/100\n",
      "56000/56000 [==============================] - 2s 33us/step - loss: 0.2415 - val_loss: 0.3044\n",
      "Epoch 22/100\n",
      "56000/56000 [==============================] - 2s 33us/step - loss: 0.2403 - val_loss: 0.3032\n",
      "Epoch 23/100\n",
      "56000/56000 [==============================] - 2s 33us/step - loss: 0.2401 - val_loss: 0.3060\n",
      "Epoch 24/100\n",
      "56000/56000 [==============================] - 2s 33us/step - loss: 0.2392 - val_loss: 0.3090\n",
      "Epoch 25/100\n",
      "56000/56000 [==============================] - 2s 33us/step - loss: 0.2383 - val_loss: 0.3087\n",
      "Epoch 26/100\n",
      "56000/56000 [==============================] - 2s 34us/step - loss: 0.2380 - val_loss: 0.3104\n",
      "Epoch 27/100\n",
      "56000/56000 [==============================] - 2s 34us/step - loss: 0.2379 - val_loss: 0.3089\n",
      "Epoch 28/100\n",
      "56000/56000 [==============================] - 2s 33us/step - loss: 0.2370 - val_loss: 0.3080\n",
      "Epoch 29/100\n",
      "56000/56000 [==============================] - 2s 33us/step - loss: 0.2364 - val_loss: 0.3090\n",
      "Epoch 30/100\n",
      "56000/56000 [==============================] - 2s 33us/step - loss: 0.2361 - val_loss: 0.3107\n",
      "Epoch 31/100\n",
      "56000/56000 [==============================] - 2s 34us/step - loss: 0.2360 - val_loss: 0.3113\n",
      "Epoch 32/100\n",
      "56000/56000 [==============================] - 2s 33us/step - loss: 0.2352 - val_loss: 0.3130\n",
      "Epoch 33/100\n",
      "56000/56000 [==============================] - 2s 34us/step - loss: 0.2347 - val_loss: 0.3149\n",
      "Epoch 34/100\n",
      "56000/56000 [==============================] - 2s 33us/step - loss: 0.2345 - val_loss: 0.3129\n",
      "Epoch 35/100\n",
      "56000/56000 [==============================] - 2s 33us/step - loss: 0.2340 - val_loss: 0.3157\n",
      "Epoch 36/100\n",
      "56000/56000 [==============================] - 2s 34us/step - loss: 0.2336 - val_loss: 0.3120\n",
      "Epoch 37/100\n",
      "56000/56000 [==============================] - 2s 33us/step - loss: 0.2326 - val_loss: 0.3124\n",
      "Epoch 38/100\n",
      "56000/56000 [==============================] - 2s 33us/step - loss: 0.2324 - val_loss: 0.3119\n",
      "Epoch 39/100\n",
      "56000/56000 [==============================] - 2s 34us/step - loss: 0.2318 - val_loss: 0.3175\n",
      "Epoch 40/100\n",
      "56000/56000 [==============================] - 2s 34us/step - loss: 0.2313 - val_loss: 0.3139\n",
      "Epoch 41/100\n",
      "56000/56000 [==============================] - 2s 34us/step - loss: 0.2313 - val_loss: 0.3203\n",
      "Epoch 42/100\n",
      "56000/56000 [==============================] - 2s 34us/step - loss: 0.2312 - val_loss: 0.3150\n",
      "Epoch 43/100\n",
      "56000/56000 [==============================] - 2s 34us/step - loss: 0.2308 - val_loss: 0.3216\n",
      "Epoch 44/100\n",
      "56000/56000 [==============================] - 2s 34us/step - loss: 0.2304 - val_loss: 0.3181\n",
      "Epoch 45/100\n",
      "56000/56000 [==============================] - 2s 33us/step - loss: 0.2303 - val_loss: 0.3177\n",
      "Epoch 46/100\n",
      "56000/56000 [==============================] - 2s 34us/step - loss: 0.2299 - val_loss: 0.3217\n",
      "Epoch 47/100\n",
      "56000/56000 [==============================] - 2s 34us/step - loss: 0.2299 - val_loss: 0.3218\n",
      "Epoch 48/100\n",
      "56000/56000 [==============================] - 2s 33us/step - loss: 0.2302 - val_loss: 0.3222\n",
      "Epoch 49/100\n",
      "56000/56000 [==============================] - 2s 34us/step - loss: 0.2293 - val_loss: 0.3230\n",
      "Epoch 50/100\n",
      "56000/56000 [==============================] - 2s 33us/step - loss: 0.2292 - val_loss: 0.3203\n",
      "Epoch 51/100\n",
      "56000/56000 [==============================] - 2s 33us/step - loss: 0.2290 - val_loss: 0.3233\n",
      "Epoch 52/100\n",
      "56000/56000 [==============================] - 2s 33us/step - loss: 0.2287 - val_loss: 0.3200\n",
      "Epoch 53/100\n",
      "56000/56000 [==============================] - 2s 33us/step - loss: 0.2285 - val_loss: 0.3243\n",
      "Epoch 54/100\n",
      "56000/56000 [==============================] - 2s 33us/step - loss: 0.2283 - val_loss: 0.3273\n",
      "Epoch 55/100\n",
      "56000/56000 [==============================] - 2s 34us/step - loss: 0.2286 - val_loss: 0.3262\n",
      "Epoch 56/100\n",
      "56000/56000 [==============================] - 2s 35us/step - loss: 0.2282 - val_loss: 0.3266\n",
      "Epoch 57/100\n",
      "56000/56000 [==============================] - 2s 34us/step - loss: 0.2282 - val_loss: 0.3277\n",
      "Epoch 58/100\n",
      "56000/56000 [==============================] - 2s 34us/step - loss: 0.2275 - val_loss: 0.3270\n",
      "Epoch 59/100\n",
      "56000/56000 [==============================] - 2s 33us/step - loss: 0.2275 - val_loss: 0.3301\n",
      "Epoch 60/100\n",
      "56000/56000 [==============================] - 2s 33us/step - loss: 0.2273 - val_loss: 0.3269\n",
      "Epoch 61/100\n",
      "56000/56000 [==============================] - 2s 33us/step - loss: 0.2276 - val_loss: 0.3298\n",
      "Epoch 62/100\n",
      "56000/56000 [==============================] - 2s 34us/step - loss: 0.2274 - val_loss: 0.3310\n",
      "Epoch 63/100\n",
      "56000/56000 [==============================] - 2s 34us/step - loss: 0.2274 - val_loss: 0.3306\n",
      "Epoch 64/100\n",
      "56000/56000 [==============================] - 2s 34us/step - loss: 0.2265 - val_loss: 0.3309\n",
      "Epoch 65/100\n",
      "56000/56000 [==============================] - 2s 35us/step - loss: 0.2267 - val_loss: 0.3286\n",
      "Epoch 66/100\n",
      "56000/56000 [==============================] - 2s 43us/step - loss: 0.2272 - val_loss: 0.3301\n",
      "Epoch 67/100\n",
      "56000/56000 [==============================] - 2s 39us/step - loss: 0.2262 - val_loss: 0.3312\n",
      "Epoch 68/100\n",
      "56000/56000 [==============================] - 2s 33us/step - loss: 0.2267 - val_loss: 0.3301\n",
      "Epoch 69/100\n",
      "56000/56000 [==============================] - 2s 33us/step - loss: 0.2265 - val_loss: 0.3311\n",
      "Epoch 70/100\n",
      "56000/56000 [==============================] - 2s 33us/step - loss: 0.2268 - val_loss: 0.3309\n",
      "Epoch 71/100\n",
      "56000/56000 [==============================] - 2s 36us/step - loss: 0.2259 - val_loss: 0.3337\n",
      "Epoch 72/100\n",
      "56000/56000 [==============================] - 2s 33us/step - loss: 0.2264 - val_loss: 0.3329\n",
      "Epoch 73/100\n",
      "56000/56000 [==============================] - 2s 33us/step - loss: 0.2257 - val_loss: 0.3342\n",
      "Epoch 74/100\n",
      "56000/56000 [==============================] - 2s 33us/step - loss: 0.2262 - val_loss: 0.3334\n",
      "Epoch 75/100\n",
      "56000/56000 [==============================] - 2s 33us/step - loss: 0.2260 - val_loss: 0.3312\n",
      "Epoch 76/100\n",
      "56000/56000 [==============================] - 2s 33us/step - loss: 0.2250 - val_loss: 0.3342\n",
      "Epoch 77/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "56000/56000 [==============================] - 2s 34us/step - loss: 0.2257 - val_loss: 0.3343\n",
      "Epoch 78/100\n",
      "56000/56000 [==============================] - 2s 33us/step - loss: 0.2254 - val_loss: 0.3351\n",
      "Epoch 79/100\n",
      "56000/56000 [==============================] - 2s 34us/step - loss: 0.2254 - val_loss: 0.3366\n",
      "Epoch 80/100\n",
      "56000/56000 [==============================] - 2s 37us/step - loss: 0.2258 - val_loss: 0.3355\n",
      "Epoch 81/100\n",
      "56000/56000 [==============================] - 2s 33us/step - loss: 0.2245 - val_loss: 0.3373\n",
      "Epoch 82/100\n",
      "56000/56000 [==============================] - 2s 33us/step - loss: 0.2248 - val_loss: 0.3355\n",
      "Epoch 83/100\n",
      "56000/56000 [==============================] - 2s 33us/step - loss: 0.2248 - val_loss: 0.3367\n",
      "Epoch 84/100\n",
      "56000/56000 [==============================] - 2s 34us/step - loss: 0.2247 - val_loss: 0.3421\n",
      "Epoch 85/100\n",
      "56000/56000 [==============================] - 2s 34us/step - loss: 0.2251 - val_loss: 0.3370\n",
      "Epoch 86/100\n",
      "56000/56000 [==============================] - 2s 33us/step - loss: 0.2248 - val_loss: 0.3375\n",
      "Epoch 87/100\n",
      "56000/56000 [==============================] - 2s 33us/step - loss: 0.2246 - val_loss: 0.3398\n",
      "Epoch 88/100\n",
      "56000/56000 [==============================] - 2s 33us/step - loss: 0.2247 - val_loss: 0.3385\n",
      "Epoch 89/100\n",
      "56000/56000 [==============================] - 2s 33us/step - loss: 0.2242 - val_loss: 0.3420\n",
      "Epoch 90/100\n",
      "56000/56000 [==============================] - 2s 34us/step - loss: 0.2248 - val_loss: 0.3372\n",
      "Epoch 91/100\n",
      "56000/56000 [==============================] - 2s 34us/step - loss: 0.2241 - val_loss: 0.3401\n",
      "Epoch 92/100\n",
      "56000/56000 [==============================] - 2s 34us/step - loss: 0.2241 - val_loss: 0.3388\n",
      "Epoch 93/100\n",
      "56000/56000 [==============================] - 2s 33us/step - loss: 0.2243 - val_loss: 0.3417\n",
      "Epoch 94/100\n",
      "56000/56000 [==============================] - 2s 33us/step - loss: 0.2243 - val_loss: 0.3399\n",
      "Epoch 95/100\n",
      "56000/56000 [==============================] - 2s 33us/step - loss: 0.2242 - val_loss: 0.3417\n",
      "Epoch 96/100\n",
      "56000/56000 [==============================] - 2s 34us/step - loss: 0.2239 - val_loss: 0.3460\n",
      "Epoch 97/100\n",
      "56000/56000 [==============================] - 2s 34us/step - loss: 0.2240 - val_loss: 0.3440\n",
      "Epoch 98/100\n",
      "56000/56000 [==============================] - 2s 33us/step - loss: 0.2238 - val_loss: 0.3389\n",
      "Epoch 99/100\n",
      "56000/56000 [==============================] - 2s 36us/step - loss: 0.2237 - val_loss: 0.3437\n",
      "Epoch 100/100\n",
      "56000/56000 [==============================] - 2s 40us/step - loss: 0.2234 - val_loss: 0.3468\n",
      "CPU times: user 4min 37s, sys: 12.5 s, total: 4min 49s\n",
      "Wall time: 3min 9s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "fit_history = logistic_classifier.fit(\n",
    "  X_train, y_train,\n",
    "  validation_data=(X_valid, y_valid),\n",
    "  epochs=100,\n",
    "  batch_size=128\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_pred_proba = logistic_classifier.predict(X_test)\n",
    "y_test_pred = np.argmax(y_test_pred_proba, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "def evaluate_classifier(clf, round_to=3):\n",
    "  datasets = [X_train, X_valid, X_test]\n",
    "  label_sets = [y_train_labels, y_valid_labels, y_test_labels]\n",
    "  for (set_label, X, labels) in zip(['train', 'validation', 'test'], datasets, label_sets):\n",
    "    y_pred_proba = clf.predict(X)\n",
    "    y_pred = np.argmax(y_pred_proba, axis=1)\n",
    "\n",
    "    accuracy = accuracy_score(labels, y_pred)\n",
    "\n",
    "    print(\n",
    "      'accuracy on {} set:\\n{}'.format(\n",
    "        set_label,\n",
    "        round(accuracy, round_to)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy on train set:\n",
      "0.942\n",
      "accuracy on validation set:\n",
      "0.918\n",
      "accuracy on test set:\n",
      "0.917\n"
     ]
    }
   ],
   "source": [
    "evaluate_classifier(logistic_classifier)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Validation vs training loss "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def plot_train_vs_validation_loss(history, offset=0):\n",
    "  train_loss = history.history['loss']\n",
    "  eval_loss = history.history['val_loss']\n",
    "  l = len(train_loss)\n",
    "  rng = np.arange(start=offset, stop=l)\n",
    "  \n",
    "  plt.plot(rng, train_loss[offset:], label='train')\n",
    "  plt.plot(rng, eval_loss[offset:], label='validation')\n",
    "  plt.legend()\n",
    "  plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAX4AAAD8CAYAAABw1c+bAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nfmOMyTAW/MYYk2Es+I0xJsP8/00H0BhgtE/0AAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f0861e6e2b0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_train_vs_validation_loss(fit_history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "plot_train_vs_validation_loss(mlp_train_loss, mlp_eval_loss, offset=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "evaluate_classifier(mlp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Different optimizers/hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "customized_mlp = mod.Module(symbol=mlp_out(num_hidden))\n",
    "\n",
    "customized_mlp.bind(data_shapes=train_iter.provide_data, label_shapes=train_iter.provide_label)\n",
    "customized_mlp.init_params(initializer=mx.init.Xavier(magnitude=2.))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "customized_mlp_train_log_list = []\n",
    "customized_mlp_eval_log_list = []\n",
    "\n",
    "%time customized_mlp.fit(\\\n",
    "  train_iter,\\\n",
    "  eval_data=valid_iter,\\\n",
    "  optimizer='adam',\\\n",
    "  optimizer_params={'learning_rate': 0.001, 'wd': 1e-3},\\\n",
    "  eval_metric='ce',\\\n",
    "  batch_end_callback=log_to_list(customized_mlp_train_log_list),\\\n",
    "  eval_batch_end_callback=log_to_list(customized_mlp_eval_log_list, data_type='Valid'),\\\n",
    "  num_epoch=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "customized_mlp_train_loss = [msg[1][4] for msg in customized_mlp_train_log_list]\n",
    "customized_mlp_eval_loss = [msg[1][4] for msg in customized_mlp_eval_log_list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "plot_train_vs_validation_loss(customized_mlp_train_loss, customized_mlp_eval_loss)\n",
    "evaluate_classifier(customized_mlp)"
   ]
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
