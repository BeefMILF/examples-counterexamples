{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import gensim\n",
    "import arxiv\n",
    "import pandas as pd\n",
    "\n",
    "import itertools\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load ML articles from arxiv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query returned 500 results\n",
      "CPU times: user 1.71 s, sys: 28.1 ms, total: 1.74 s\n",
      "Wall time: 6.49 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "search_query = 'text summarization'\n",
    "\n",
    "results = arxiv.query(search_query=search_query,\n",
    "                          max_results=500)\n",
    "\n",
    "print('Query returned {} results'.format(len(results)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Display some basic information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "********************\n",
      "Bengali text summarization by sentence extraction\n",
      "********************\n",
      "Kamal Sarkar\n",
      "2012-01-11T04:56:59Z\n",
      "Text summarization is a process to produce an abstract or a summary by\n",
      "selecting significant portion of the information from one or more texts. In an\n",
      "automatic text summarization process, a text is given to the computer and the\n",
      "computer returns a shorter less redundant extract or abstract of the original\n",
      "text(s). Many techniques have been developed for summarizing English text(s).\n",
      "But, a very few attempts have been made for Bengali text summarization. This\n",
      "paper presents a method for Bengali text summarization which extracts important\n",
      "sentences from a Bengali document to produce a summary.\n",
      "\n",
      "********************\n",
      "A Semantic Relevance Based Neural Network for Text Summarization and\n",
      "  Text Simplification\n",
      "********************\n",
      "Shuming Ma, Xu Sun\n",
      "2017-10-06T09:06:33Z\n",
      "Text summarization and text simplification are two major ways to simplify the\n",
      "text for poor readers, including children, non-native speakers, and the\n",
      "functionally illiterate. Text summarization is to produce a brief summary of\n",
      "the main ideas of the text, while text simplification aims to reduce the\n",
      "linguistic complexity of the text and retain the original meaning. Recently,\n",
      "most approaches for text summarization and text simplification are based on the\n",
      "sequence-to-sequence model, which achieves much success in many text generation\n",
      "tasks. However, although the generated simplified texts are similar to source\n",
      "texts literally, they have low semantic relevance. In this work, our goal is to\n",
      "improve semantic relevance between source texts and simplified texts for text\n",
      "summarization and text simplification. We introduce a Semantic Relevance Based\n",
      "neural model to encourage high semantic similarity between texts and summaries.\n",
      "In our model, the source text is represented by a gated attention encoder,\n",
      "while the summary representation is produced by a decoder. Besides, the\n",
      "similarity score between the representations is maximized during training. Our\n",
      "experiments show that the proposed model outperforms the state-of-the-art\n",
      "systems on two benchmark corpus.\n",
      "\n",
      "********************\n",
      "Automatic Keyword Extraction for Text Summarization: A Survey\n",
      "********************\n",
      "Santosh Kumar Bharti, Korra Sathya Babu\n",
      "2017-04-11T11:20:19Z\n",
      "In recent times, data is growing rapidly in every domain such as news, social\n",
      "media, banking, education, etc. Due to the excessiveness of data, there is a\n",
      "need of automatic summarizer which will be capable to summarize the data\n",
      "especially textual data in original document without losing any critical\n",
      "purposes. Text summarization is emerged as an important research area in recent\n",
      "past. In this regard, review of existing work on text summarization process is\n",
      "useful for carrying out further research. In this paper, recent literature on\n",
      "automatic keyword extraction and text summarization are presented since text\n",
      "summarization process is highly depend on keyword extraction. This literature\n",
      "includes the discussion about different methodology used for keyword extraction\n",
      "and text summarization. It also discusses about different databases used for\n",
      "text summarization in several domains along with evaluation matrices. Finally,\n",
      "it discusses briefly about issues and research challenges faced by researchers\n",
      "along with future direction.\n",
      "\n",
      "********************\n",
      "Test Model for Text Categorization and Text Summarization\n",
      "********************\n",
      "Khushboo Thakkar, Urmila Shrawankar\n",
      "2013-05-10T08:06:15Z\n",
      "Text Categorization is the task of automatically sorting a set of documents\n",
      "into categories from a predefined set and Text Summarization is a brief and\n",
      "accurate representation of input text such that the output covers the most\n",
      "important concepts of the source in a condensed manner. Document Summarization\n",
      "is an emerging technique for understanding the main purpose of any kind of\n",
      "documents. This paper presents a model that uses text categorization and text\n",
      "summarization for searching a document based on user query.\n",
      "\n",
      "********************\n",
      "Different approaches for identifying important concepts in probabilistic\n",
      "  biomedical text summarization\n",
      "********************\n",
      "Milad Moradi, Nasser Ghadiri\n",
      "2017-05-30T14:37:31Z\n",
      "Automatic text summarization tools help users in biomedical domain to acquire\n",
      "their intended information from various textual resources more efficiently.\n",
      "Some of the biomedical text summarization systems put the basis of their\n",
      "sentence selection approach on the frequency of concepts extracted from the\n",
      "input text. However, it seems that exploring other measures rather than the\n",
      "frequency for identifying the valuable content of the input document, and\n",
      "considering the correlations existing between concepts may be more useful for\n",
      "this type of summarization. In this paper, we describe a Bayesian summarizer\n",
      "for biomedical text documents. The Bayesian summarizer initially maps the input\n",
      "text to the Unified Medical Language System (UMLS) concepts, then it selects\n",
      "the important ones to be used as classification features. We introduce\n",
      "different feature selection approaches to identify the most important concepts\n",
      "of the text and to select the most informative content according to the\n",
      "distribution of these concepts. We show that with the use of an appropriate\n",
      "feature selection approach, the Bayesian biomedical summarizer can improve the\n",
      "performance of summarization. We perform extensive evaluations on a corpus of\n",
      "scientific papers in biomedical domain. The results show that the Bayesian\n",
      "summarizer outperforms the biomedical summarizers that rely on the frequency of\n",
      "concepts, the domain-independent and baseline methods based on the\n",
      "Recall-Oriented Understudy for Gisting Evaluation (ROUGE) metrics. Moreover,\n",
      "the results suggest that using the meaningfulness measure and considering the\n",
      "correlations of concepts in the feature selection step lead to a significant\n",
      "increase in the performance of summarization.\n",
      "\n",
      "********************\n",
      "Quantifying the informativeness for biomedical literature summarization:\n",
      "  An itemset mining method\n",
      "********************\n",
      "Milad Moradi, Nasser Ghadiri\n",
      "2017-05-26T04:30:39Z\n",
      "Objective: Automatic text summarization tools can help users in the\n",
      "biomedical domain to access information efficiently from a large volume of\n",
      "scientific literature and other sources of text documents. In this paper, we\n",
      "propose a summarization method that combines itemset mining and domain\n",
      "knowledge to construct a concept-based model and to extract the main subtopics\n",
      "from an input document. Our summarizer quantifies the informativeness of each\n",
      "sentence using the support values of itemsets appearing in the sentence.\n",
      "Methods: To address the concept-level analysis of text, our method initially\n",
      "maps the original document to biomedical concepts using the UMLS. Then, it\n",
      "discovers the essential subtopics of the text using a data mining technique,\n",
      "namely itemset mining, and constructs the summarization model. The employed\n",
      "itemset mining algorithm extracts a set of frequent itemsets containing\n",
      "correlated and recurrent concepts of the input document. The summarizer selects\n",
      "the most related and informative sentences and generates the final summary.\n",
      "Results: We evaluate the performance of our itemset-based summarizer using the\n",
      "Recall-Oriented Understudy for Gisting Evaluation (ROUGE) metrics, performing a\n",
      "set of experiments. The results show that the itemset-based summarizer performs\n",
      "better than the compared methods. The itemset-based summarizer achieves the\n",
      "best scores for all the assessed ROUGE metrics . Conclusion: Compared to the\n",
      "statistical, similarity, and word frequency methods, the proposed method\n",
      "demonstrates that the summarization model obtained from the concept extraction\n",
      "and itemset mining provides the summarizer with an effective metric for\n",
      "measuring the informative content of sentences. This can lead to an improvement\n",
      "in the performance of biomedical literature summarization.\n",
      "\n",
      "********************\n",
      "Dimensionality on Summarization\n",
      "********************\n",
      "Hai Zhuge\n",
      "2015-07-01T12:39:50Z\n",
      "Summarization is one of the key features of human intelligence. It plays an\n",
      "important role in understanding and representation. With rapid and continual\n",
      "expansion of texts, pictures and videos in cyberspace, automatic summarization\n",
      "becomes more and more desirable. Text summarization has been studied for over\n",
      "half century, but it is still hard to automatically generate a satisfied\n",
      "summary. Traditional methods process texts empirically and neglect the\n",
      "fundamental characteristics and principles of language use and understanding.\n",
      "This paper summarizes previous text summarization approaches in a\n",
      "multi-dimensional classification space, introduces a multi-dimensional\n",
      "methodology for research and development, unveils the basic characteristics and\n",
      "principles of language use and understanding, investigates some fundamental\n",
      "mechanisms of summarization, studies the dimensions and forms of\n",
      "representations, and proposes a multi-dimensional evaluation mechanisms.\n",
      "Investigation extends to the incorporation of pictures into summary and to the\n",
      "summarization of videos, graphs and pictures, and then reaches a general\n",
      "summarization framework.\n",
      "\n",
      "********************\n",
      "Text Summarization Techniques: A Brief Survey\n",
      "********************\n",
      "Mehdi Allahyari, Seyedamin Pouriyeh, Mehdi Assefi, Saeid Safaei, Elizabeth D. Trippe, Juan B. Gutierrez, Krys Kochut\n",
      "2017-07-28T16:37:16Z\n",
      "In recent years, there has been a explosion in the amount of text data from a\n",
      "variety of sources. This volume of text is an invaluable source of information\n",
      "and knowledge which needs to be effectively summarized to be useful. In this\n",
      "review, the main approaches to automatic text summarization are described. We\n",
      "review the different processes for summarization and describe the effectiveness\n",
      "and shortcomings of the different methods.\n",
      "\n",
      "********************\n",
      "Fuzzy Logic Based Method for Improving Text Summarization\n",
      "********************\n",
      "Ladda Suanmali, Naomie Salim, Mohammed Salem Binwahlan\n",
      "2009-06-25T13:19:07Z\n",
      "Text summarization can be classified into two approaches: extraction and\n",
      "abstraction. This paper focuses on extraction approach. The goal of text\n",
      "summarization based on extraction approach is sentence selection. One of the\n",
      "methods to obtain the suitable sentences is to assign some numerical measure of\n",
      "a sentence for the summary called sentence weighting and then select the best\n",
      "ones. The first step in summarization by extraction is the identification of\n",
      "important features. In our experiment, we used 125 test documents in DUC2002\n",
      "data set. Each document is prepared by preprocessing process: sentence\n",
      "segmentation, tokenization, removing stop word, and word stemming. Then, we use\n",
      "8 important features and calculate their score for each sentence. We propose\n",
      "text summarization based on fuzzy logic to improve the quality of the summary\n",
      "created by the general statistic method. We compare our results with the\n",
      "baseline summarizer and Microsoft Word 2007 summarizers. The results show that\n",
      "the best average precision, recall, and f-measure for the summaries were\n",
      "obtained by fuzzy method.\n",
      "\n",
      "********************\n",
      "Tone Biased MMR Text Summarization\n",
      "********************\n",
      "Mayank Chaudhari, Aakash Nelson Mattukoyya\n",
      "2018-02-27T10:25:07Z\n",
      "Text summarization is an interesting area for researchers to develop new\n",
      "techniques to provide human like summaries for vast amounts of information.\n",
      "Summarization techniques tend to focus on providing accurate representation of\n",
      "content, and often the tone of the content is ignored. Tone of the content sets\n",
      "a baseline for how a reader perceives the content. As such being able to\n",
      "generate summary with tone that is appropriate for the reader is important. In\n",
      "our work we implement Maximal Marginal Relevance [MMR] based multi-document\n",
      "text summarization and propose a naive model to change tone of the\n",
      "summarization by setting a bias to specific set of words and restricting other\n",
      "words in the summarization output. This bias towards a specified set of words\n",
      "produces a summary whose tone is same as tone of specified words.\n",
      "\n",
      "********************\n",
      "Artex is AnotheR TEXt summarizer\n",
      "********************\n",
      "Juan-Manuel Torres-Moreno\n",
      "2012-10-11T18:21:01Z\n",
      "This paper describes Artex, another algorithm for Automatic Text\n",
      "Summarization. In order to rank sentences, a simple inner product is calculated\n",
      "between each sentence, a document vector (text topic) and a lexical vector\n",
      "(vocabulary used by a sentence). Summaries are then generated by assembling the\n",
      "highest ranked sentences. No ruled-based linguistic post-processing is\n",
      "necessary in order to obtain summaries. Tests over several datasets (coming\n",
      "from Document Understanding Conferences (DUC), Text Analysis Conferences (TAC),\n",
      "evaluation campaigns, etc.) in French, English and Spanish have shown that\n",
      "summarizer achieves interesting results.\n",
      "\n",
      "********************\n",
      "Extractive Text Summarization using Neural Networks\n",
      "********************\n",
      "Aakash Sinha, Abhishek Yadav, Akshay Gahlot\n",
      "2018-02-27T19:48:51Z\n",
      "Text Summarization has been an extensively studied problem. Traditional\n",
      "approaches to text summarization rely heavily on feature engineering. In\n",
      "contrast to this, we propose a fully data-driven approach using feedforward\n",
      "neural networks for single document summarization. We train and evaluate the\n",
      "model on standard DUC 2002 dataset which shows results comparable to the state\n",
      "of the art models. The proposed model is scalable and is able to produce the\n",
      "summary of arbitrarily sized documents by breaking the original document into\n",
      "fixed sized parts and then feeding it recursively to the network.\n",
      "\n",
      "********************\n",
      "Improving Multi-Document Summarization via Text Classification\n",
      "********************\n",
      "Ziqiang Cao, Wenjie Li, Sujian Li, Furu Wei\n",
      "2016-11-28T16:53:06Z\n",
      "Developed so far, multi-document summarization has reached its bottleneck due\n",
      "to the lack of sufficient training data and diverse categories of documents.\n",
      "Text classification just makes up for these deficiencies. In this paper, we\n",
      "propose a novel summarization system called TCSum, which leverages plentiful\n",
      "text classification data to improve the performance of multi-document\n",
      "summarization. TCSum projects documents onto distributed representations which\n",
      "act as a bridge between text classification and summarization. It also utilizes\n",
      "the classification results to produce summaries of different styles. Extensive\n",
      "experiments on DUC generic multi-document summarization datasets show that,\n",
      "TCSum can achieve the state-of-the-art performance without using any\n",
      "hand-crafted features and has the capability to catch the variations of summary\n",
      "styles with respect to different text categories.\n",
      "\n",
      "********************\n",
      "Hybrid Approach for Single Text Document Summarization using Statistical\n",
      "  and Sentiment Features\n",
      "********************\n",
      "Chandra Shekhar Yadav, Aditi Sharan\n",
      "2016-01-03T05:55:56Z\n",
      "Summarization is a way to represent same information in concise way with\n",
      "equal sense. This can be categorized in two type Abstractive and Extractive\n",
      "type. Our work is focused around Extractive summarization. A generic approach\n",
      "to extractive summarization is to consider sentence as an entity, score each\n",
      "sentence based on some indicative features to ascertain the quality of sentence\n",
      "for inclusion in summary. Sort the sentences on the score and consider top n\n",
      "sentences for summarization. Mostly statistical features have been used for\n",
      "scoring the sentences. We are proposing a hybrid model for a single text\n",
      "document summarization. This hybrid model is an extraction based approach,\n",
      "which is combination of Statistical and semantic technique. The hybrid model\n",
      "depends on the linear combination of statistical measures : sentence position,\n",
      "TF-IDF, Aggregate similarity, centroid, and semantic measure. Our idea to\n",
      "include sentiment analysis for salient sentence extraction is derived from the\n",
      "concept that emotion plays an important role in communication to effectively\n",
      "convey any message hence, it can play a vital role in text document\n",
      "summarization. For comparison we have generated five system summaries Proposed\n",
      "Work, MEAD system, Microsoft system, OPINOSIS system, and Human generated\n",
      "summary, and evaluation is done using ROUGE score.\n",
      "\n",
      "********************\n",
      "Faithful to the Original: Fact Aware Neural Abstractive Summarization\n",
      "********************\n",
      "Ziqiang Cao, Furu Wei, Wenjie Li, Sujian Li\n",
      "2017-11-13T06:34:29Z\n",
      "Unlike extractive summarization, abstractive summarization has to fuse\n",
      "different parts of the source text, which inclines to create fake facts. Our\n",
      "preliminary study reveals nearly 30% of the outputs from a state-of-the-art\n",
      "neural summarization system suffer from this problem. While previous\n",
      "abstractive summarization approaches usually focus on the improvement of\n",
      "informativeness, we argue that faithfulness is also a vital prerequisite for a\n",
      "practical abstractive summarization system. To avoid generating fake facts in a\n",
      "summary, we leverage open information extraction and dependency parse\n",
      "technologies to extract actual fact descriptions from the source text. The\n",
      "dual-attention sequence-to-sequence framework is then proposed to force the\n",
      "generation conditioned on both the source text and the extracted fact\n",
      "descriptions. Experiments on the Gigaword benchmark dataset demonstrate that\n",
      "our model can greatly reduce fake summaries by 80%. Notably, the fact\n",
      "descriptions also bring significant improvement on informativeness since they\n",
      "often condense the meaning of the source text.\n",
      "\n",
      "********************\n",
      "Revisiting Summarization Evaluation for Scientific Articles\n",
      "********************\n",
      "Arman Cohan, Nazli Goharian\n",
      "2016-04-01T20:06:46Z\n",
      "Evaluation of text summarization approaches have been mostly based on metrics\n",
      "that measure similarities of system generated summaries with a set of human\n",
      "written gold-standard summaries. The most widely used metric in summarization\n",
      "evaluation has been the ROUGE family. ROUGE solely relies on lexical overlaps\n",
      "between the terms and phrases in the sentences; therefore, in cases of\n",
      "terminology variations and paraphrasing, ROUGE is not as effective. Scientific\n",
      "article summarization is one such case that is different from general domain\n",
      "summarization (e.g. newswire data). We provide an extensive analysis of ROUGE's\n",
      "effectiveness as an evaluation metric for scientific summarization; we show\n",
      "that, contrary to the common belief, ROUGE is not much reliable in evaluating\n",
      "scientific summaries. We furthermore show how different variants of ROUGE\n",
      "result in very different correlations with the manual Pyramid scores. Finally,\n",
      "we propose an alternative metric for summarization evaluation which is based on\n",
      "the content relevance between a system generated summary and the corresponding\n",
      "human written summaries. We call our metric SERA (Summarization Evaluation by\n",
      "Relevance Analysis). Unlike ROUGE, SERA consistently achieves high correlations\n",
      "with manual scores which shows its effectiveness in evaluation of scientific\n",
      "article summarization.\n",
      "\n",
      "********************\n",
      "Conceptual Text Summarizer: A new model in continuous vector space\n",
      "********************\n",
      "Mohammad Ebrahim Khademi, Mohammad Fakhredanesh, Seyed Mojtaba Hoseini\n",
      "2018-02-05T13:34:02Z\n",
      "Traditional methods of summarization are not cost-effective and possible\n",
      "today. Extractive summarization is a process that helps to extract the most\n",
      "important sentences from a text automatically and generates a short informative\n",
      "summary. In this work, we propose an unsupervised method to summarize Persian\n",
      "texts. This method is a novel hybrid approach that clusters the concepts of the\n",
      "text using deep learning and statistical methods. Although the proposed method\n",
      "is language independent, we focus on Persian text summarization in this work.\n",
      "First we produce a word embedding based on Hamshahri2 corpus and a dictionary\n",
      "of word frequencies. Then the proposed algorithm extracts the keywords of the\n",
      "document, clusters its concepts, and finally ranks the sentences to produce the\n",
      "summary. We evaluated the proposed method on Pasokh single-document data set\n",
      "using the ROUGE evaluation measure. Without using any hand-crafted features,\n",
      "our proposed method achieves competitive performance.\n",
      "\n",
      "********************\n",
      "LCSTS: A Large Scale Chinese Short Text Summarization Dataset\n",
      "********************\n",
      "Baotian Hu, Qingcai Chen, Fangze Zhu\n",
      "2016-02-19T16:35:35Z\n",
      "Automatic text summarization is widely regarded as the highly difficult\n",
      "problem, partially because of the lack of large text summarization data set.\n",
      "Due to the great challenge of constructing the large scale summaries for full\n",
      "text, in this paper, we introduce a large corpus of Chinese short text\n",
      "summarization dataset constructed from the Chinese microblogging website Sina\n",
      "Weibo, which is released to the public\n",
      "{http://icrc.hitsz.edu.cn/Article/show/139.html}. This corpus consists of over\n",
      "2 million real Chinese short texts with short summaries given by the author of\n",
      "each text. We also manually tagged the relevance of 10,666 short summaries with\n",
      "their corresponding short texts. Based on the corpus, we introduce recurrent\n",
      "neural network for the summary generation and achieve promising results, which\n",
      "not only shows the usefulness of the proposed corpus for short text\n",
      "summarization research, but also provides a baseline for further research on\n",
      "this topic.\n",
      "\n",
      "********************\n",
      "Measuring the Effect of Discourse Relations on Blog Summarization\n",
      "********************\n",
      "Shamima Mithun, Leila Kosseim\n",
      "2017-08-19T04:01:43Z\n",
      "The work presented in this paper attempts to evaluate and quantify the use of\n",
      "discourse relations in the context of blog summarization and compare their use\n",
      "to more traditional and factual texts. Specifically, we measured the usefulness\n",
      "of 6 discourse relations - namely comparison, contingency, illustration,\n",
      "attribution, topic-opinion, and attributive for the task of text summarization\n",
      "from blogs. We have evaluated the effect of each relation using the TAC 2008\n",
      "opinion summarization dataset and compared them with the results with the DUC\n",
      "2007 dataset. The results show that in both textual genres, contingency,\n",
      "comparison, and illustration relations provide a significant improvement on\n",
      "summarization content; while attribution, topic-opinion, and attributive\n",
      "relations do not provide a consistent and significant improvement. These\n",
      "results indicate that, at least for summarization, discourse relations are just\n",
      "as useful for informal and affective texts as for more traditional news\n",
      "articles.\n",
      "\n",
      "********************\n",
      "A Semantic Approach to Summarization\n",
      "********************\n",
      "Divyanshu Bhartiya, Ashudeep Singh\n",
      "2014-06-04T20:22:30Z\n",
      "Sentence extraction based summarization methods has some limitations as it\n",
      "doesn't go into the semantics of the document. Also, it lacks the capability of\n",
      "sentence generation which is intuitive to humans. Here we present a novel\n",
      "method to summarize text documents taking the process to semantic levels with\n",
      "the use of WordNet and other resources, and using a technique for sentence\n",
      "generation. We involve semantic role labeling to get the semantic\n",
      "representation of text and use of segmentation to form clusters of the related\n",
      "pieces of text. Picking out the centroids and sentence generation completes the\n",
      "task. We evaluate our system against human composed summaries and also present\n",
      "an evaluation done by humans to measure the quality attributes of our\n",
      "summaries.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "n_examples = 20\n",
    "\n",
    "for entry in results[:n_examples]:\n",
    "  print(20 * '*')\n",
    "  print(entry['title'])\n",
    "  print(20 * '*')\n",
    "  print(', '.join(entry['authors']))\n",
    "  print(entry['date'])\n",
    "  print(entry['summary'])\n",
    "  print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "articles_df = pd.DataFrame(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['affiliation', 'arxiv_comment', 'arxiv_primary_category', 'arxiv_url',\n",
       "       'author', 'author_detail', 'authors', 'doi', 'guidislink', 'id',\n",
       "       'journal_reference', 'links', 'pdf_url', 'published',\n",
       "       'published_parsed', 'summary', 'summary_detail', 'tags', 'title',\n",
       "       'title_detail', 'updated', 'updated_parsed'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "articles_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>affiliation</th>\n",
       "      <th>arxiv_comment</th>\n",
       "      <th>arxiv_primary_category</th>\n",
       "      <th>arxiv_url</th>\n",
       "      <th>author</th>\n",
       "      <th>author_detail</th>\n",
       "      <th>authors</th>\n",
       "      <th>doi</th>\n",
       "      <th>guidislink</th>\n",
       "      <th>id</th>\n",
       "      <th>...</th>\n",
       "      <th>pdf_url</th>\n",
       "      <th>published</th>\n",
       "      <th>published_parsed</th>\n",
       "      <th>summary</th>\n",
       "      <th>summary_detail</th>\n",
       "      <th>tags</th>\n",
       "      <th>title</th>\n",
       "      <th>title_detail</th>\n",
       "      <th>updated</th>\n",
       "      <th>updated_parsed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>{'term': 'cs.IR', 'scheme': 'http://arxiv.org/...</td>\n",
       "      <td>http://arxiv.org/abs/1201.2240v1</td>\n",
       "      <td>Kamal Sarkar</td>\n",
       "      <td>{'name': 'Kamal Sarkar'}</td>\n",
       "      <td>[Kamal Sarkar]</td>\n",
       "      <td>None</td>\n",
       "      <td>True</td>\n",
       "      <td>http://arxiv.org/abs/1201.2240v1</td>\n",
       "      <td>...</td>\n",
       "      <td>http://arxiv.org/pdf/1201.2240v1</td>\n",
       "      <td>2012-01-11T04:56:59Z</td>\n",
       "      <td>(2012, 1, 11, 4, 56, 59, 2, 11, 0)</td>\n",
       "      <td>Text summarization is a process to produce an ...</td>\n",
       "      <td>{'language': None, 'value': 'Text summarizatio...</td>\n",
       "      <td>[{'label': None, 'term': 'cs.IR', 'scheme': 'h...</td>\n",
       "      <td>Bengali text summarization by sentence extraction</td>\n",
       "      <td>{'language': None, 'value': 'Bengali text summ...</td>\n",
       "      <td>2012-01-11T04:56:59Z</td>\n",
       "      <td>(2012, 1, 11, 4, 56, 59, 2, 11, 0)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>{'term': 'cs.CL', 'scheme': 'http://arxiv.org/...</td>\n",
       "      <td>http://arxiv.org/abs/1710.02318v1</td>\n",
       "      <td>Xu Sun</td>\n",
       "      <td>{'name': 'Xu Sun'}</td>\n",
       "      <td>[Shuming Ma, Xu Sun]</td>\n",
       "      <td>None</td>\n",
       "      <td>True</td>\n",
       "      <td>http://arxiv.org/abs/1710.02318v1</td>\n",
       "      <td>...</td>\n",
       "      <td>http://arxiv.org/pdf/1710.02318v1</td>\n",
       "      <td>2017-10-06T09:06:33Z</td>\n",
       "      <td>(2017, 10, 6, 9, 6, 33, 4, 279, 0)</td>\n",
       "      <td>Text summarization and text simplification are...</td>\n",
       "      <td>{'language': None, 'value': 'Text summarizatio...</td>\n",
       "      <td>[{'label': None, 'term': 'cs.CL', 'scheme': 'h...</td>\n",
       "      <td>A Semantic Relevance Based Neural Network for ...</td>\n",
       "      <td>{'language': None, 'value': 'A Semantic Releva...</td>\n",
       "      <td>2017-10-06T09:06:33Z</td>\n",
       "      <td>(2017, 10, 6, 9, 6, 33, 4, 279, 0)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>None</td>\n",
       "      <td>12 pages, 4 figures</td>\n",
       "      <td>{'term': 'cs.CL', 'scheme': 'http://arxiv.org/...</td>\n",
       "      <td>http://arxiv.org/abs/1704.03242v1</td>\n",
       "      <td>Korra Sathya Babu</td>\n",
       "      <td>{'name': 'Korra Sathya Babu'}</td>\n",
       "      <td>[Santosh Kumar Bharti, Korra Sathya Babu]</td>\n",
       "      <td>None</td>\n",
       "      <td>True</td>\n",
       "      <td>http://arxiv.org/abs/1704.03242v1</td>\n",
       "      <td>...</td>\n",
       "      <td>http://arxiv.org/pdf/1704.03242v1</td>\n",
       "      <td>2017-04-11T11:20:19Z</td>\n",
       "      <td>(2017, 4, 11, 11, 20, 19, 1, 101, 0)</td>\n",
       "      <td>In recent times, data is growing rapidly in ev...</td>\n",
       "      <td>{'language': None, 'value': 'In recent times, ...</td>\n",
       "      <td>[{'label': None, 'term': 'cs.CL', 'scheme': 'h...</td>\n",
       "      <td>Automatic Keyword Extraction for Text Summariz...</td>\n",
       "      <td>{'language': None, 'value': 'Automatic Keyword...</td>\n",
       "      <td>2017-04-11T11:20:19Z</td>\n",
       "      <td>(2017, 4, 11, 11, 20, 19, 1, 101, 0)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>None</td>\n",
       "      <td>Pages: 07 Figures : 07</td>\n",
       "      <td>{'term': 'cs.IR', 'scheme': 'http://arxiv.org/...</td>\n",
       "      <td>http://arxiv.org/abs/1305.2831v1</td>\n",
       "      <td>Urmila Shrawankar</td>\n",
       "      <td>{'name': 'Urmila Shrawankar'}</td>\n",
       "      <td>[Khushboo Thakkar, Urmila Shrawankar]</td>\n",
       "      <td>None</td>\n",
       "      <td>True</td>\n",
       "      <td>http://arxiv.org/abs/1305.2831v1</td>\n",
       "      <td>...</td>\n",
       "      <td>http://arxiv.org/pdf/1305.2831v1</td>\n",
       "      <td>2013-05-10T08:06:15Z</td>\n",
       "      <td>(2013, 5, 10, 8, 6, 15, 4, 130, 0)</td>\n",
       "      <td>Text Categorization is the task of automatical...</td>\n",
       "      <td>{'language': None, 'value': 'Text Categorizati...</td>\n",
       "      <td>[{'label': None, 'term': 'cs.IR', 'scheme': 'h...</td>\n",
       "      <td>Test Model for Text Categorization and Text Su...</td>\n",
       "      <td>{'language': None, 'value': 'Test Model for Te...</td>\n",
       "      <td>2013-05-10T08:06:15Z</td>\n",
       "      <td>(2013, 5, 10, 8, 6, 15, 4, 130, 0)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>{'term': 'cs.CL', 'scheme': 'http://arxiv.org/...</td>\n",
       "      <td>http://arxiv.org/abs/1605.02948v3</td>\n",
       "      <td>Nasser Ghadiri</td>\n",
       "      <td>{'name': 'Nasser Ghadiri'}</td>\n",
       "      <td>[Milad Moradi, Nasser Ghadiri]</td>\n",
       "      <td>None</td>\n",
       "      <td>True</td>\n",
       "      <td>http://arxiv.org/abs/1605.02948v3</td>\n",
       "      <td>...</td>\n",
       "      <td>http://arxiv.org/pdf/1605.02948v3</td>\n",
       "      <td>2016-05-10T11:33:33Z</td>\n",
       "      <td>(2016, 5, 10, 11, 33, 33, 1, 131, 0)</td>\n",
       "      <td>Automatic text summarization tools help users ...</td>\n",
       "      <td>{'language': None, 'value': 'Automatic text su...</td>\n",
       "      <td>[{'label': None, 'term': 'cs.CL', 'scheme': 'h...</td>\n",
       "      <td>Different approaches for identifying important...</td>\n",
       "      <td>{'language': None, 'value': 'Different approac...</td>\n",
       "      <td>2017-05-30T14:37:31Z</td>\n",
       "      <td>(2017, 5, 30, 14, 37, 31, 1, 150, 0)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  affiliation           arxiv_comment  \\\n",
       "0        None                    None   \n",
       "1        None                    None   \n",
       "2        None     12 pages, 4 figures   \n",
       "3        None  Pages: 07 Figures : 07   \n",
       "4        None                    None   \n",
       "\n",
       "                              arxiv_primary_category  \\\n",
       "0  {'term': 'cs.IR', 'scheme': 'http://arxiv.org/...   \n",
       "1  {'term': 'cs.CL', 'scheme': 'http://arxiv.org/...   \n",
       "2  {'term': 'cs.CL', 'scheme': 'http://arxiv.org/...   \n",
       "3  {'term': 'cs.IR', 'scheme': 'http://arxiv.org/...   \n",
       "4  {'term': 'cs.CL', 'scheme': 'http://arxiv.org/...   \n",
       "\n",
       "                           arxiv_url             author  \\\n",
       "0   http://arxiv.org/abs/1201.2240v1       Kamal Sarkar   \n",
       "1  http://arxiv.org/abs/1710.02318v1             Xu Sun   \n",
       "2  http://arxiv.org/abs/1704.03242v1  Korra Sathya Babu   \n",
       "3   http://arxiv.org/abs/1305.2831v1  Urmila Shrawankar   \n",
       "4  http://arxiv.org/abs/1605.02948v3     Nasser Ghadiri   \n",
       "\n",
       "                   author_detail                                    authors  \\\n",
       "0       {'name': 'Kamal Sarkar'}                             [Kamal Sarkar]   \n",
       "1             {'name': 'Xu Sun'}                       [Shuming Ma, Xu Sun]   \n",
       "2  {'name': 'Korra Sathya Babu'}  [Santosh Kumar Bharti, Korra Sathya Babu]   \n",
       "3  {'name': 'Urmila Shrawankar'}      [Khushboo Thakkar, Urmila Shrawankar]   \n",
       "4     {'name': 'Nasser Ghadiri'}             [Milad Moradi, Nasser Ghadiri]   \n",
       "\n",
       "    doi  guidislink                                 id  \\\n",
       "0  None        True   http://arxiv.org/abs/1201.2240v1   \n",
       "1  None        True  http://arxiv.org/abs/1710.02318v1   \n",
       "2  None        True  http://arxiv.org/abs/1704.03242v1   \n",
       "3  None        True   http://arxiv.org/abs/1305.2831v1   \n",
       "4  None        True  http://arxiv.org/abs/1605.02948v3   \n",
       "\n",
       "                   ...                                             pdf_url  \\\n",
       "0                  ...                    http://arxiv.org/pdf/1201.2240v1   \n",
       "1                  ...                   http://arxiv.org/pdf/1710.02318v1   \n",
       "2                  ...                   http://arxiv.org/pdf/1704.03242v1   \n",
       "3                  ...                    http://arxiv.org/pdf/1305.2831v1   \n",
       "4                  ...                   http://arxiv.org/pdf/1605.02948v3   \n",
       "\n",
       "              published                      published_parsed  \\\n",
       "0  2012-01-11T04:56:59Z    (2012, 1, 11, 4, 56, 59, 2, 11, 0)   \n",
       "1  2017-10-06T09:06:33Z    (2017, 10, 6, 9, 6, 33, 4, 279, 0)   \n",
       "2  2017-04-11T11:20:19Z  (2017, 4, 11, 11, 20, 19, 1, 101, 0)   \n",
       "3  2013-05-10T08:06:15Z    (2013, 5, 10, 8, 6, 15, 4, 130, 0)   \n",
       "4  2016-05-10T11:33:33Z  (2016, 5, 10, 11, 33, 33, 1, 131, 0)   \n",
       "\n",
       "                                             summary  \\\n",
       "0  Text summarization is a process to produce an ...   \n",
       "1  Text summarization and text simplification are...   \n",
       "2  In recent times, data is growing rapidly in ev...   \n",
       "3  Text Categorization is the task of automatical...   \n",
       "4  Automatic text summarization tools help users ...   \n",
       "\n",
       "                                      summary_detail  \\\n",
       "0  {'language': None, 'value': 'Text summarizatio...   \n",
       "1  {'language': None, 'value': 'Text summarizatio...   \n",
       "2  {'language': None, 'value': 'In recent times, ...   \n",
       "3  {'language': None, 'value': 'Text Categorizati...   \n",
       "4  {'language': None, 'value': 'Automatic text su...   \n",
       "\n",
       "                                                tags  \\\n",
       "0  [{'label': None, 'term': 'cs.IR', 'scheme': 'h...   \n",
       "1  [{'label': None, 'term': 'cs.CL', 'scheme': 'h...   \n",
       "2  [{'label': None, 'term': 'cs.CL', 'scheme': 'h...   \n",
       "3  [{'label': None, 'term': 'cs.IR', 'scheme': 'h...   \n",
       "4  [{'label': None, 'term': 'cs.CL', 'scheme': 'h...   \n",
       "\n",
       "                                               title  \\\n",
       "0  Bengali text summarization by sentence extraction   \n",
       "1  A Semantic Relevance Based Neural Network for ...   \n",
       "2  Automatic Keyword Extraction for Text Summariz...   \n",
       "3  Test Model for Text Categorization and Text Su...   \n",
       "4  Different approaches for identifying important...   \n",
       "\n",
       "                                        title_detail               updated  \\\n",
       "0  {'language': None, 'value': 'Bengali text summ...  2012-01-11T04:56:59Z   \n",
       "1  {'language': None, 'value': 'A Semantic Releva...  2017-10-06T09:06:33Z   \n",
       "2  {'language': None, 'value': 'Automatic Keyword...  2017-04-11T11:20:19Z   \n",
       "3  {'language': None, 'value': 'Test Model for Te...  2013-05-10T08:06:15Z   \n",
       "4  {'language': None, 'value': 'Different approac...  2017-05-30T14:37:31Z   \n",
       "\n",
       "                         updated_parsed  \n",
       "0    (2012, 1, 11, 4, 56, 59, 2, 11, 0)  \n",
       "1    (2017, 10, 6, 9, 6, 33, 4, 279, 0)  \n",
       "2  (2017, 4, 11, 11, 20, 19, 1, 101, 0)  \n",
       "3    (2013, 5, 10, 8, 6, 15, 4, 130, 0)  \n",
       "4  (2017, 5, 30, 14, 37, 31, 1, 150, 0)  \n",
       "\n",
       "[5 rows x 22 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "articles_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extract keywords from summaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 10.7 s, sys: 19.5 ms, total: 10.8 s\n",
      "Wall time: 10.8 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "articles_df['summary_keywords'] = articles_df['summary'].apply(gensim.summarization.keywords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "articles_df['summary_keywords'] = articles_df['summary_keywords'].str.split('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "********************\n",
      "Bengali text summarization by sentence extraction\n",
      "********************\n",
      "keywords: ['texts', 'text summarization', 'significant', 'summarizing']\n",
      "\n",
      "********************\n",
      "A Semantic Relevance Based Neural Network for Text Summarization and\n",
      "  Text Simplification\n",
      "********************\n",
      "keywords: ['text', 'texts', 'semantic', 'model', 'attention', 'summary', 'summaries', 'meaning', 'generation', 'generated', 'readers', 'non']\n",
      "\n",
      "********************\n",
      "Automatic Keyword Extraction for Text Summarization: A Survey\n",
      "********************\n",
      "keywords: ['recent', 'research', 'researchers', 'summarizer', 'summarize', 'summarization', 'different', 'matrices', 'data', 'social', 'banking', 'challenges']\n",
      "\n",
      "********************\n",
      "Test Model for Text Categorization and Text Summarization\n",
      "********************\n",
      "keywords: ['text', 'documents', 'document', 'manner', 'summarization', 'user']\n",
      "\n",
      "********************\n",
      "Different approaches for identifying important concepts in probabilistic\n",
      "  biomedical text summarization\n",
      "********************\n",
      "keywords: ['summarizer', 'summarizers', 'text summarization', 'features', 'feature', 'selection', 'selects', 'select', 'content', 'concepts', 'evaluations', 'evaluation', 'biomedical', 'methods', 'medical', 'important']\n",
      "\n",
      "********************\n",
      "Quantifying the informativeness for biomedical literature summarization:\n",
      "  An itemset mining method\n",
      "********************\n",
      "keywords: ['summarizer', 'itemsets', 'method', 'methods', 'itemset mining', 'text summarization', 'concept', 'concepts', 'information', 'informativeness', 'informative', 'metric', 'metrics performing', 'documents', 'document', 'rouge', 'subtopics', 'summary', 'performance', 'performs']\n",
      "\n",
      "********************\n",
      "Dimensionality on Summarization\n",
      "********************\n",
      "keywords: ['summarization', 'summarizes', 'texts', 'text', 'investigates', 'investigation', 'mechanisms', 'automatic', 'automatically', 'summary', 'space', 'characteristics']\n",
      "\n",
      "********************\n",
      "Text Summarization Techniques: A Brief Survey\n",
      "********************\n",
      "keywords: ['text', 'different']\n",
      "\n",
      "********************\n",
      "Fuzzy Logic Based Method for Improving Text Summarization\n",
      "********************\n",
      "keywords: ['sentence', 'sentences', 'summarization', 'summarizer', 'summarizers', 'word', 'data', 'important', 'statistic', 'precision', 'best', 'fuzzy']\n",
      "\n",
      "********************\n",
      "Tone Biased MMR Text Summarization\n",
      "********************\n",
      "keywords: ['summarization', 'sets', 'setting', 'set', 'techniques', 'tone', 'words', 'summaries', 'accurate', 'summary', 'maximal']\n",
      "\n",
      "********************\n",
      "Artex is AnotheR TEXt summarizer\n",
      "********************\n",
      "keywords: ['text', 'vector', 'summaries', 'conferences', 'inner', 'describes', 'post']\n",
      "\n",
      "********************\n",
      "Extractive Text Summarization using Neural Networks\n",
      "********************\n",
      "keywords: ['sized documents', 'document', 'summarization', 'model', 'models', 'duc', 'results']\n",
      "\n",
      "********************\n",
      "Improving Multi-Document Summarization via Text Classification\n",
      "********************\n",
      "keywords: ['text', 'documents', 'multi summarization', 'styles']\n",
      "\n",
      "********************\n",
      "Hybrid Approach for Single Text Document Summarization using Statistical\n",
      "  and Sentiment Features\n",
      "********************\n",
      "keywords: ['sentence', 'sentences', 'extractive', 'extraction', 'summary', 'summaries', 'role', 'sentiment', 'score', 'scoring', 'model', 'generic', 'generated', 'measures', 'measure', 'similarity']\n",
      "\n",
      "********************\n",
      "Faithful to the Original: Fact Aware Neural Abstractive Summarization\n",
      "********************\n",
      "keywords: ['fake', 'extractive', 'extraction', 'extract', 'extracted', 'facts', 'fact', 'summarization abstractive', 'generating', 'generation', 'significant', 'different', 'parse']\n",
      "\n",
      "********************\n",
      "Revisiting Summarization Evaluation for Scientific Articles\n",
      "********************\n",
      "keywords: ['rouge', 'summarization', 'scientific', 'sera', 'analysis', 'summaries', 'summary', 'scores', 'written', 'metrics', 'metric']\n",
      "\n",
      "********************\n",
      "Conceptual Text Summarizer: A new model in continuous vector space\n",
      "********************\n",
      "keywords: ['methods', 'method', 'document', 'informative', 'hybrid', 'evaluated', 'evaluation', 'extractive', 'extract', 'extracts', 'text', 'texts', 'summarization', 'summarize', 'word']\n",
      "\n",
      "********************\n",
      "LCSTS: A Large Scale Chinese Short Text Summarization Dataset\n",
      "********************\n",
      "keywords: ['texts', 'text summarization', 'summaries', 'summary', 'chinese short', 'corpus', 'promising', 'large', 'recurrent']\n",
      "\n",
      "********************\n",
      "Measuring the Effect of Discourse Relations on Blog Summarization\n",
      "********************\n",
      "keywords: ['summarization', 'texts', 'text', 'relations', 'relation', 'news', 'contingency', 'opinion']\n",
      "\n",
      "********************\n",
      "A Semantic Approach to Summarization\n",
      "********************\n",
      "keywords: ['semantics', 'semantic', 'summarize text', 'summarization', 'composed', 'role']\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for __, row in itertools.islice(articles_df.iterrows(), n_examples):\n",
    "  print(20 * '*')\n",
    "  print(row['title'])\n",
    "  print(20 * '*')\n",
    "  print('keywords:', row['summary_keywords'])\n",
    "  print()\n"
   ]
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
