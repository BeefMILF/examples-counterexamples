{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Approximate Nearest Neighbors for search\n",
    "\n",
    "* Author\n",
    "* some terminology\n",
    "* kNN\n",
    "* Applications\n",
    "    - information retrieval\n",
    "    - useful in more complex tasks (pattern matching)\n",
    "* Why ANN\n",
    "* Approaches\n",
    "    - LSH\n",
    "    - Projection-based\n",
    "    - Graph-based\n",
    "    - Product Quantization\n",
    "* (Python) Libraries\n",
    "    - annoy\n",
    "    - NMSLib\n",
    "    - Rii\n",
    "    - ~~faiss~~"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Author\n",
    "\n",
    "#### Jakub Bartczuk\n",
    "\n",
    "- Machine learning engineer, previously developer\n",
    "- Currently: Data scientist @Semantive\n",
    "- Math background (Theoretical Math BSc)\n",
    "\n",
    "For a previous year heavily into deep learning. Actually I started using ANN tools in a DL-based project!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## kNN Terminology\n",
    "\n",
    "<img style=\"float: right;\" src=\"https://upload.wikimedia.org/wikipedia/commons/thumb/e/e7/KnnClassification.svg/279px-KnnClassification.svg.png\">\n",
    "\n",
    "Let's fix some notation:\n",
    "\n",
    "$X$ - dataset, $X \\subset \\mathbb{R}^d$\n",
    "\n",
    "\n",
    "$d(x,y)$ - distance between $x$ and $y$\n",
    "\n",
    "\n",
    "$\\| x - y \\|_{p} = \\sqrt[p]{\\sum_{i<d} (x_i - y_i)^p}$ - $p$th norm, for example $ \\| x - y \\|_{2} $ - Euclidean norm\n",
    "\n",
    "$q$ - query vector\n",
    "\n",
    "$N_k(q, X)$ - $k$ nearest neighbors of $q$ in $X$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## kNN\n",
    "\n",
    "Probably one of the simplest ML methods.\n",
    "\n",
    "Pros\n",
    "- doesn't make any assumption on distribution in supervised learning (nonparametric)\n",
    "- quite easy to interpret prediction - just look at the neighbors!\n",
    "\n",
    "Cons\n",
    "- prone to overfitting\n",
    "- suffers from 'curse of dimensionality'\n",
    "- **costly inference**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Applications"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Information retrieval\n",
    "\n",
    "Traditionally IR is mostly done for text data that is easily searchable in a different way (inverted index).\n",
    "\n",
    "kNN enables IR of any data that we can vectorize."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "###### Examples:\n",
    "- music (there are many tools for extracting features from sound)\n",
    "- images (just run your favourite CNN and extract activations from some modestly sized layer)\n",
    "- text again - extract features using Doc2Vec or some RNN of your choice\n",
    "- actually anything for which you have a DL model that captures relevant structure\n",
    "\n",
    "A concrete example of music search can be found in [findkit](https://github.com/lambdaofgod/findkit) library."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Useful in other tasks\n",
    "\n",
    "- kNN is used as intermediate step in manifold learning algorithms (picture from megaman documentation) <img src=\"http://mmp2.github.io/megaman/_images/spectra_Halpha.png\" style=\"float: right;\" width=\"350\"/>\n",
    "\n",
    "- Texture synthesis - for example see [Style-Transfer via Texture-Synthesis](https://arxiv.org/pdf/1609.03057.pdf) (that's a non-CNN based Style Transfer method)\n",
    "\n",
    "- Density estimation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## kNN drawbacks\n",
    "\n",
    "### suffers from 'curse of dimensionality'\n",
    "\n",
    "#### Actually not such a big problem in applications:\n",
    "- Most interesting feature extraction methods don't have more than a couple of hundreds-dimensional outputs. \n",
    "- 'manifold hypothesis' tends to hold in practice.\n",
    "\n",
    "### costly inference\n",
    "\n",
    "That's actually the biggest problem. \n",
    "\n",
    "TODO: Big O complexity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Approximate kNN\n",
    "\n",
    "Idea: don't do *exact* kNN. Try to retrieve neighbors *with high probability*.\n",
    "\n",
    "### Approaches\n",
    "- Locality Sensitive Hashing\n",
    "- Graph-based\n",
    "- Product Quantization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Locality Sensitive Hashing (LSH)\n",
    "\n",
    "LSH in a nutshell:\n",
    "\n",
    "Pick family of functions $H$ and a probability measure on $H$ such that $$P_{h \\in H}(h(x) = h(y)) = d(x, y)$$\n",
    "\n",
    "If we pick a subset of $H$ we can approximate $d(x, y)$ by checking how many hash values differ.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "\n",
    "\n",
    "### Note\n",
    "\n",
    "The choice of hashing functions depends heavily on $d$.\n",
    "\n",
    "#### Examples:\n",
    "\n",
    "Let $d(x, y) = \\|x - y\\|_2$ \n",
    "\n",
    "Pick random vectors $v_i$ and define $h_i(x)= sign(\\langle x | v_i \\rangle$)\n",
    "\n",
    "Why it works? Johnson-Lindenstrauss lemma."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Projection-based approach\n",
    "\n",
    "Similar to 'random projections' LSH.\n",
    "\n",
    "\n",
    "$sign(\\langle x | v_i \\rangle$ is used to build a tree which we can traverse to find nearest neighbors.\n",
    "\n",
    "Trees can be aggregated into forests. This makes approximate search better."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "<img src=\"https://camo.githubusercontent.com/d6bf20e534ab76b67c731b566859a24149a4bf80/68747470733a2f2f7261772e6769746875622e636f6d2f73706f746966792f616e6e6f792f6d61737465722f616e6e2e706e67\" width=\"400\"/>\n",
    "\n",
    "Source: annoy's github page"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Graph-based\n",
    "\n",
    "\n",
    "Small World Graphs\n",
    "\n",
    "#### Notes\n",
    "Kleinberg's article, P2P networks\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Product Quantization\n",
    "\n",
    "Idea: use something like hashes, but built using k-means.\n",
    "\n",
    "It's helpful to split features into groups and then compute k-means separately for subsets (hence *product* quantization)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Bibliography\n",
    "\n",
    "### Papers\n",
    "\n",
    "[The Small-World Phenomenon: An Algorithmic Perspective](https://www.cs.cornell.edu/home/kleinber/swn.ps) - intro to theoretical underpinnings of graph approach\n",
    "\n",
    "[Product quantization for nearest neighbor search](https://lear.inrialpes.fr/pubs/2011/JDS11/jegou_searching_with_quantization.pdf) - intro to PQ for kNN\n",
    "\n",
    "[annoy](https://github.com/spotify/annoy)"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "nnets",
   "language": "python",
   "name": "nnets"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
